# Cognitive Ergonomics in Design

**COURSE**

---

## Introduction

> The origins of ergonomics relate to ***fitting the task to the person***

Cognitive ergonomics is about considering the impact of how people think, reason, understand
and act in design of all aspects of life, and use it to make better decisions when creating products.

Taking cognitive factors into account can prevent incidents and errors in systems. The example 
of the [**Three Mile Island**](https://en.wikipedia.org/wiki/Three_Mile_Island_accident) incident demontrastes the important of human factors.
In march 1979, bad design and bad user interfaces lead to human errors and then a nuclear incident. It was the most significant accident in
the U.S commercial nuclear power plant history (see chapter **Human error and automation** for more details).

The course is outlined with the following chapters:

- **Memory and attention**
- **Human workload**
- **Situation awareness**
- **Mental models**
- **Human error and automation**
- **Decision making and expertise**
- **Joint cognitive systems**

--- 

## Memory

### Memory structures

When trying to describe how the memory works, two types of structures can be noted:

- **Spatial**: memories are stored in a specific location, and *remembering* is a retrieval process involving a specific spatial search through the mind,
- **Parallel distributed processing**: memories stored in the form of connections among units and not stored in a single place.

### Memory models

More precisely, the memory presents many states, components and other elements that makes it more complex. Psychologist have been
trying to explain it through diverse models for many years. However critized, these models have influenced memory research.

#### Multi-store model

Proposed in 1968 by **Richard Atkinson** and **Richard Siffrin**, the multi-store model (or *modal model*) asserts that the memory is split
in three separate stores: **Sensory**, **Short-term** and **Long-term**.

The sensory stores describes the very brief availibility of memories related to envionmental stimulus. While it is generally
agreed that there is a sensory store for each sense, most of the research in the area has focused on the visual and auditory systems. The **iconic** store
refers to the visual system (delay of ~0.5 seconds, limited to the field of vision) and the **echoic** store focuses on the auditory system (delay of ~2 seconds). Unless attended, most of the information in sensory stores decays and is quickly forgotten.

When sensory memory is attended, it is transferred to the short-term store. This store holds information for a longer duration, but has a
very limited capacity: seven, plus or minus two items. However the short-term memory is susceptible to loss of information when
distracted. The duration can be extended if the information is **rehearsed**.

If that information is rehearsed thoroughly for a longer period of time, it is transferred to the long-term store. This store 
is more or less a permanent store that can hold information over extremely long periods of time. It is in fact assumed to be nearly
limitless in its duration and capacity. Information stored there can be transferred back to the short-term store where it can be
attended to and manipulated.

> **Criticism**: the modal model has been intensively critized over the following aspects:
>
> - Over simplified,
> - Evidence that the short-term probably behaves differently for different senses,
> - Fails to explain how information is really stored in the long-term store,
> - Focuses more on the structure instead of the actual process involved in memory and learning.

#### Working memory model

Proposed in 1974 by **Alan Baddely** and **Graham Hitch** proposed the working memory model in attempt to present a more
accurate model than the modal model by introducing a three part **working memory** replacing the short-term store. In 2000, they 
added a fourth component in the model. These components are:

- **Central executive**: acts as a supervisory system controlling the flow of information from and to its slave systems: the phonological loop and 
the visuo-spatial sketchpad,
- **Phonological loop**: stores information in a phonological form (speech-based, verbal content),
- **Visuo-visual sketch**: stores the spatial and/or visual data,
- **Episodic buffer**: conjoins information from the phonological loop and the visuo-visual sketch (visual, spatial and verbal information) with long-term memory (chronological information) into a single episodic representation (e.g. the memory of a story or a movie scene).

> **Advantages**: 
> 
> - Explains real world memory tasks (e.g. mental arithmetic, verbal reasoning),
> - Explains better the experiences of brain damaged patients,
> - Less focused on verbal rehearsal for retention.
> 
> **Disadvantage**: Difficulty to measure the capacity of the central executive.

### Long-term memory

The long-term memory does not store memories in one unified structure, as might be seen in a computer's hard disk drive. Instead, the long-term memory is typically divided into two major components: **explicit** memory and **implicit** memory.

#### Explicit memory

Also called the *declarative memory*, the explicit memory refers to all memories that are consciously available. It is the conscious, intentional recollection of factual information, previous experiences and concepts. People use explicit memory throughout the day, such as remembering the time of an appointment or recollecting an event from years ago. The explicit memory is divided in four major memory types:

- **Episodic**: storage and recollection of observational information attached to specific life-events (*someone's name*, *the memory of watching a movie*, *the memory of meeting someone*),
- **Semantic**: general world knowledge (facts, ideas, meaning and concepts) that can be articulated and is independant of personal experience (*languages*, *structures*, *classifications*, *objects*),
- **Autobiographical**: combination of episodic and semantic memory to contain the information on what the self is, what the self was, and what the self can be,
- **Spatial**: memory responsible for the recording of information about the environment and spatial orientation (*navigation*, *recognition of familiar places*, *map reading*).

#### Implicit memory

Also called the *procedural memory*, the implicity memory refers to the use of objects, or the movements of the body, generally to skills. It is acquired and used unconsciously, and can affect thoughts and behaviours. People use implicit memory every day such as tying their shoes or riding a bicycle, without consciously thinking about these activities.

### False memories

Evidence and studies have shown that although people are highly confident in their memories, the details of the memories can be forgotten and altered. A false memory is a phenomenon where a person recalls something that did not happen or differently from the way it happened. This phenomenon was initially investigated by the psychological pioneers **Pierre Janet** and **Sigmund Freud**. **Elizabeth Loftus** has since been a lead researcher in memory recovery and false memories. False memories can be created by suggestibility, activation of associated information, the incorporation of misinformation or source misattribution.

A common example to explain false memories is the case of the car crash and the distorted perceptions of it. In 1974, Loftus and Palmer conducted an experiment where they showed participants the video of a car crash. Later, they were asked questions about that same accident. The questions were asked differently to each participants, where for example a word in the question would change: "*About how fast were the cars going when they smashed/collided/bumped/hit/contacted each other?*". The results showed that the estimated speed was affected by the verb used. In addition, a week later, a question about the presence of broken glass on the accident was asked, and revealed that more participants that were asked the first question with the verb "*smashed*" remembered broken glass, although there was none.

### Flashbulb memory

A flashbulb memory is highly detailed, exceptionnally vivid "*snapshot*" of the moment and circumstances in which a piece of surprising and consequential news was heard. This type of memory include six main characteristic features: *place*, *ongoing activity*, *informant*, *own effect*, *other effect* and *aftermath*. Generally, the determinants of a flashbulb memory are a high level of surprise, a high level of consequentiality, and perhaps emotional arousal. An example of such a memory is the generally very detailed memories of the events of 9/11, and how many people remember exactly what they were doing the moment they learned about these events. 

Flashbulb memories however remain a controversial idea among psychologists, with some believing that these memories are not different from any other autobiographical memory because they rely on elements of personal importance, consequentiality, emotion and surprise. Other researchers believe it is an entirely distinct type of memory that forms differently and perhaps in different parts of the brain.

### Misplacing objects

Misplacing objects is something that happens very often to most individuals (Sarah Brill if you read this, big up to your Burgerking experience). Four main cognitive errors leading to misplaced objects are:

- **Absent-mindness**: mental condition in which a person experiences low levels of attention and frequent distraction (object put in unusual places),
- **Updating errors**: when a person cannot remember which of several usual places an object is in,
- **Detection failures**: when a person has an object in front of them but can't *detect* it,
- **Context effects**: distortions from other elements within the environment.

Common techniques to locate missing objects are: 

- **Action replay**: reconstruct sequence of actions,
- **Mental walk**: visualise possible object locations,
- **Reality monitoring**: generate images of placing the object in various locations and decide whether these correspond to reality,
- **Physical search**.

---

## Attention

Attention is the behavioral and cognitive process of selectively concentrating on a discrete aspect of information, whether deemed subjective or objective, while ignoring other perceivable information. Also described as the allocation of limited cognitive processing resources, attention remains a major area of investigation to determine the source of the sensor cues and signals that generate attention and the relationship between ofhter concepts like working memory and psychological vigilance.

### Types of attention

Attention is commonly split into four different types:

- **Selective**: ability to direct attention on several sources of information to determine whether a particular event has occured (*a doctor reading a hospital screen*),
- **Focused**: ability to direct attention on a single source of information without interruption or interference from either external or internal factors or stimuli (*a tennis court supervisor*),
- **Divided**: ability to direct attention to two or more separated tasks performed simultaneously (*cooking a meal*),
- **Sustained**: ability to continuously maintain focus on a task or event over a long period of time (*monitoring camera screen for security measures*).

### Attention models

#### Broadbent's filter model

In 1958, **Broadbent** proposed an attention model that postulates that physicial characteristics of messages are used to select one message for further processing and that all others are lost. This models proposes that information from all the stimuli at any given time enters an unilimited capacity sensory buffer, and is then filtered based on physical characteristics (*pitch*, *color*, *loudness*, *direction*). Because the human brain has a limited capacity to process information, this filter is designed to prevent the information-processing system from becoming overloaded. According to Broadbent the meaning of any of the messages is not taken into account at all by the filter.  All semantic processing is carried out after the filter has selected the message to pay attention to. So every message that is not attended would not be understood.

> **Criticism**: In addition to several criticism regarding the experiments that lead to the Broadbent's model (possible other explanations than the filter theory), a major issue with this model is that it does not account for the *Cocktail Party Effect*, because unattended messages are filtered out before the meaning can be processed (hearing someone call your name when not focused on it should then be impossible).

#### Treisman's attenuation model

In 1964, **Treisman** completes Broadbent's theory by specifying that the filter attenuates rather than eliminates the unattended material. This attenuation is like turning down the volume, so that if you have 4 sources of sound in one room, you can turn down or attenuate 3 in order to attend the fourth. This means that people can still process the meaning of unattended messages.

> **Criticism**: This model overcomes some of the Broadbent's model (the Cocktail Party Effect), but has been criticized regarding the lack of precision on the nature of the attenuation process and Treisman does not explain how exactly semantic analysis work.

#### Late selection model

In 1963, **Deutsch & Deutsch** proposed a model where all stimuli get processed in full, with the most important or relevant stimulus determining the response. In other words, they suggested that the selection does not occus on the basis of an early-selection filter, but after stimuli have already been identified. This theory hence locates the attentional filter later in the processing, after which all material processed upto this point ad judged to be most important is elaborated more fully.

> **Criticism**: The main criticism received for this theory is how wasteful it appears, with its thorough processing of all information before selection of admittance into working memory.

#### Capacity model

In 1973, **Kahneman** proposed a theory which is based around the idea of mental efforts. It proposes that some activities are more demanding and therefore require more mental effort than others. Kahneman thus believes in the existence of a Central Processor which operates a Central Allocation Policy, constantly evaluating the demands made by each task and adjusting attention accordingly. In addition, the total available processing capacities could be increased or decreased by  factors such as arousal

> **Criticism**: The main criticism for this theory ist that by developing skills, it would become impossible to accurately evaluate the demands required for each task and hence adjust attention accordingly.

#### Perceptual load model

In 1995, **Lavie** presented the perceptual load theory as a potential resolution to the early/late selection debate. Lavie attempts to resolve this debate by stating that both early and late selection occur varying on the stimulus presented. This variation in stimilus is explained as a notion of high or low perceptual load. This perceptual load refers to the complexity of the physical stimuli (particularly the distractor stimuli). Because Lavie gives the assumption that all of the attentional resources naturally have to be used up, a low load task would process more of the distractors to exhaust mental resources, and therefore the distractors would cause a greatee inference. On the other hand, in high load situations, as all the attentional resources are used up, distractors would cause less inference, if not at all. In other words, if the task-relevant stimulus uses all of the attentional resources, then none of the task-irrelevant stimuli (distractors) will be processed.

> **Criticism**: This theory has criticized regarding several points, notably how the notion of perceptual load is in fact dilution, and that this theory is not a solution t the early/late debate. A main critique is also how a visual cue can eliminate the inference effect supposedly created by perceptual load.

### Detection theory

In many taks that require thorough attention, the concept of signal detection plays an important part. Detection theory (1954) measures the ability to differentiate between information-bearing patterns (the signals) and random patterns that distract from the information (the noise). The theory states that characteristics such as experience, expectations, physiological state and other factors can affect the ability to detect relevant information. There are four possible outcomes when detecting:

| | Signal present | Signal absent
| -- | -- | --
| Signal detected | **Hit** | False alarm
| Signal not detected | Miss | **Correct rejection**

<!-- --- 

## Fitt's List

The Fitt's List, also known as HABA-MABA (*Humans Are Better At*-*Machines Are Better At*), is a list of statements regarding the abilities of humans and machines, which is used to determine the allocation of task assignment. In others words, it used to determine if a person or a machine could better a function required by a task or a system, with the ultimate goal to increase efficiency, safety, quality and profit-margins.

The first version of that list, from 1951, is the following table:

| HABA | MABA
| -- | --
| Detect a small amout of visual or acoustic energy | Quicly respond to control signals and apply great force smoothly and precisely
| Perceive patterns of light or sound | Perform repetitive tasks
| Improvise and use flexible procedures | Store information briefly and then erase it completely
| Store very large amounts of information for long periods and recall facts at the appropriate time | Reason deductively, including computational ability
| Reason inductively | Handle high complex operations at once
| Exercise judgement | 

Of course, multiple elements of that list are outdated, and hence a more recent one is presented (2017): 

| HABA | MABA
| -- | --
| Common sense | Natural language
| Dilemmas | Pattern identification
| Morals | Locating knowledge 
| Compassion | Machine learning
| Imagination | Eliminate bias 
| Dreaming | Endless capacity
| Abstraction | 
| Generalisation |  -->

--- 

## Human Workload

The workload is the notion of amount of labor, efforts, attention, focus and resources a human can manage while conducting a task. This concept is important because humans have limited capability for processing information, holding items in memory, making decisions and performing tasks. Excess workload can result in human performance issues such as slower task completion and errors such as slips, lapses or mistakes. Underload can also lead to issues such as boredom, loss of situation awareness and reduced alertness. These issues may be more relevant in critical times suchs as incidents.

### Measuring workload

It is hence important to be able to measure and assess mental workload in tasks to improve performance and reduce issues. There are four considerations to take into account to measure mental workload:

- **Sensitivity**: ability to detect changes in the workload experience by an operator,
- **Diagnosticity**: ability to understand the nature of changes in the workload,
- **Validity**: ensure that the measured changes in workload are not from external interferences,
- **Reliability**: stability and consistency of the measures,
- **Intrusiveness**: interference of the measure on the task performance leading to contaminated workload measures,
- **Usability**: ease of use (both for participat and experimenter),
- **Operator acceptance**: ensure that no change in performance is due to the operator awareness.

There are four aspects to measure to represent mental workload:

- **Primary task**: measuring how the nature of the main task and different demands impact performance,
- **Secondary task**: measuring how adding a secondary task (varying in difficulty) impact performance for both tasks,
- **Subjective**: self-report methods to measure workload from the operator's opinion,
- **Physiological/Psycho-physiological**: measuring changes in physiological parameters indicating changes in workload.

#### Primary task measures

When measuring the primary task, the main goal is to detect and understand changes in performance as demands are modified. The number of errors made, speed of performance or reaction time are frequently used as primary-task performance measures. There are several thorough methods to achieve this (*Analytic approach (Welford, 1978)* or *Synthetic method (Chiles & Allusi, 1979)*), but a combination of many is possible to obtain measurements of the workload.
It is important to note that primary measures can be unreliable, and that the workload can increase while performance remains unchanged. In addition, the specific individuals and taks involved in the measurement might also alter the results.

#### Secondary task measures

Adding a secondary task to the operator's primary task aims to discover the balance and allocation of workload, based on the fact that humans have a limited capacity to gather and process information. By looking at the performance of each task, the researcher can assess the operator's workload capacity. There are two way to do this: 

- **Loading**: the operator is instructed to avoid making errors on the secondary task. If the limit capacity is reached, then the primary task performance is degraded,
- **Non-loading**: the operator is instructed to avoid making errors on the primary task. The operator then tends to attend to the secondary task only when time is available.

It is important to take into consideration the intrusiveness of this measurement, as the secondary task will impact the general performance. In addition, primary and secondary tasks must use the same type of resources.

#### Subjective measures

Subjective measures refers to collecting information on the workload by asking the operators to rate the level of mental workload they felt to accomplish a task. This is done through self-reports methods such as interviews and questionnaires. These measures can be unidimensional (general index of the workload) or multidimensional (more in-depth measures assessing the nature of the workload). A multidimensional approach assumes that the workload is a complex phenomenon derived from multiple factors, and that the variations in the dimensions can be defined and evaluated more precisely. These measures will differ from individuals to others, as the emphasis on dimensions are different for each. 

An example of a multidimensional rating is the NASA-TLX scale, evaluating the mental demand, physical demand, temporal demand, effort, performance and frustration level of an indidividual. Another technique is the SWAT (*Subjective Workload Assessment Technique*) that splits the scale in dimensions of time load, mental effort load and psychological stress load.

#### Physiological measures

The physiological measures consist in using physical indicators to detect workload. For example, an elevated heart rate might indicate an intense activity, as could other indicators such as pupil diameter. A very thorough method is to examine brain waves, but is a very expensive and complex measurement. Other metrics such as body chemicals or auditory canal temperature can also be used.

### Wicken's multiple resources theory

In 1984, Wickens proposes a theory where the human operator does not have one single information processing that can be tapped, but several different pools of resources that can be tapped simultaneously. Depending on the nature of the task, these resources may have to process information sequentially if the different tasks require the same pool of resources, or can be processed in parallel if the task requires different resources. This theory allows system desigers to predict when:

- Tasks can be performed concurrently,
- Tasks will interefere with each other,
- Increases in the difficulty of onne task will result in a loss of performance of another task.
