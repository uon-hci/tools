# Studying Human Performance - Methods

**COURSE**

---

## Introduction

> **Ergonomics** is the scientific discipline cocerned with the understanding of interactions among humans and other elements of a system, in order to optimise human well-being and overall system performance.

The aim of this course is to be able to **analyse products and workplaces** using a range of different methods, to **compare and contrast different methodological approaches**, to **evaluate methods** and statistical techniques, to **demonstrate the application of specific methods** in practical contexts ; in order to solve Human Factors-related problems.

---

## Choosing methods

The understanding of methods is the core matter of this subject. A method is a "*way of proceeding or doing something*", and in Human Factors, allow for the collection of data. Methods need to be **clear**, **structured** and **repeatable**.

The **context** of the studies in which methods are used define purposes, roles and data that make up for many different methods. It is hence very important to understand the context of these studies, and how it impacts the use of methods.

### Study types

Three study types are observed: **Laboratory**, **Simulation** and **Field**. These types are compared with the following table:

|               | Laboratory/Simulation | Field 
| ------------- | ------------- |  -------
| Advantages    | More control  | Real task
| Disadvantages | Limited scope and accuracy  | Unplanned events (danger, interruptions)

### Affecting factors

In addition to the study type, there are numerous factors affecting the choice of methods:

- Amount of participants,
- Motivation (*research*, *consultancy*),
- Location,
- Objective,
- Types of desired results,
- Stakeholders, sponsors and funders.

### *Good* methods

The choice of a method significantly depends on the context of the study. However it doesn't define the quality of a method. *What is a good method?*
**Five requirements** define the quality of a method:

- **Validity**: does the method measure what it is supposed to measure?
- **Reliability**: is the method stable? (consistent over various measurements, between/within researchers),
- **Sensitivity**: is the method able to detect effects of interest? (the more sensible the more accurate),
- **Usability**: is the method easy to learn and implement?
- **Resources**: how expensive and demanding (cost, expertise) is the method? 

### Types of measure

When doing a study, the type of measures defines the methods used and the data collected. In most ergonomics works, the following measure types are assessed:

- **Performance**: Task achivement, errors,
- **Demands**: Task time, physical and mental workload,
- **Behaviour**: Body movements,
- **Knowledge**: Subjective responses to a *test* situation,
- **Opinions**: Ratings, preferences.

### Method types

A simple classification splits all available methods into **three categories**:

- Observation,
- Self report,
- Use of archival data.

For all methods, the **type of output** and **validity** are also differentiated. There is first the matter of **objective** or **subjective** validity:

- **Objective**: clamining the describe a true and correct reality, independent of those involved in the research process,
- **Subjective**: based on data derived from observations of events as they occur, or from interviews.

Finally, the data can be split in two categories:

- **Qualitative**: data classification of objects based on attributes and properties,
- **Quantitative**: data measuread and expressed numerically.

---

## Planning and designing studies

### Defining the problem, aim and hypotheses

The first step in designing a study is to clearly define the problem and issues that require investigation, and what will
be achived by doing it. This is usually represented by a system of **hypotheses**, or *statements of the predicted outcome*. As 
studies manipulate variables and data, the aim of these hypotheses is to predict, understand and validate the relationships between said variables.
Conventionally, there are two types of hypothesis:

- **Experimental**, or *H1*, that predicts a dependent relationship between variables,
- **Null**, or *H0*, that states that variables are not dependent (one does not impact the other).

### Identify the research variables

The said variables are split in three categories:

- **Independant variables** (*IV*): variables manipulated by the experimented, related to the individual, task, system or environment,
- **Dependant variables** (*DV*): variables being measured in the experiment, not under the control of the experimenter, possibly affected by the IVs,
- **Controlled variables**: variables that need to be kept constant during the experiment.

### Choose the research setting

The research setting (previously mentioned as *study type*), needs to be considered through the **advantages** and **disadvantages** between Laboratory and Field studies, as well as if it is actually *possible* to implement one based on the nature of the study. The following table describes the key elements for choosing:

**Field**

| Advantages    | Disadvantage  |
| ------------- | ------------- |  
| Realistic     | Hard to set up |
| Easier to generalise results | May take longer
| Real participants | Difficulty to access real participants
| -- | Many uncontrolled variables
| -- | Harder to control variables

**Laboratory**

| Advantages    | Disadvantage  |
| ------------- | ------------- |  
| Easy to set up | Artificial
| Shorter | Participants less motivated
| Easy to control variables | May not be able to controll all extraneous variables
| Easy to perform comparative tests | May be expensive

### Select the participants sample

It is important to properly select the **sample**, the sall group that is representative of the **population**. This sample must be the most representative of the population possible, in order to make more general statements about the results.

There are multiple types of sampling, depending on if the notion of probability accuracy is desired. The three major ones are:

- **Random**: selecting random participants, with each particiant having an equal chance of being selected,
- **Systematic**: selecting every *nth* participant,
- **Stratified random**: first diving the population into meaningful groups, then selecting randomly.

In other situtions, the participants are selected in a more *favored* way, when the basic selection techniques seen previously are not precise enough and the sample needs to be very specific. The **non-probability** sample techniques are:

- **Purposive**: satisfying the specific needs of a project,
- **Conveniance sampling**: nearest, easiest, cheapest, most convenient.

Finally, the resources and costs required to mobilize a sample need to be balanced with the potential results, and the confidence that
the results will be significant.

### Defining the experimental design

The number and arrangement of the variables is an important part of the study. The aim is to ensure that the IVs are the only systematic difference between
the experimental groups, also called the **internal validity**. It is also important to consider the measurement of the DVs, such as the data is commonly quantitative, easy to collect, valid, reliable, senstive and ethical.

### Allocate participants to the experimental conditions

There are two ways to allocate and distribute the participants across the IVs:

- **Within**: every participant completes every experimental condition,
- **Between**: different participants are allocated to each experimental condition.

### Ethics

When doing studies with real participants, ethics play an important part in carrying out the experiments. It is required that they should give **informed consent**, based on sufficient information on the study (goals, duration, instruction, type of data collected, use of data). They should also be ensured protection from harm, privacy and a right to withdraw at any moment.

--- 

## Conducting the study

### Preparing the experiment

Planning an preparing before conducting the study can be a lengthy process, but is necessary. Once designed, piloting the study with *trial* members allows to make sure everything is in order and as desired. The practical details such as appointements, timescales or idenfication must be thoroughly planned. Finally the various types of equipment required for the experiments must be properly prepared in order to conduct the study with consistency.

### Analyzing the data

Once the data is collected, analyzing it is a complex process. A common way to do so is the following:

1. **Transcribe**, **examine** and **outline** the data using tools such as charts, tables ; observing patterns, distributions and tendencies,
2. **Identify** the type of data: nominal (categories), ordinal (ordered) or interval (ordered with equal intervals).
3. **Statiscally test** the data based on the purpose of the study and the experimental design,
4. **Draw conclusions**.

### Presenting results and drawing conclusions

Results can be represented visually through charts, figures and tables. *Descriptive* and *inferential* statistics are also commonly used.
Based on the drawn conslusions (*reject*, *fail to reject*), a wider discussion must be made regarding the strength of the findings, and how they can be generalized to other contexts.

--- 

## Self report methods

### Questionnaire

Questionnaires are good tools to survey **large populations**, while ensuring a **high response rate**.
It is however a complex method that requires careful planning and proper question wording. Designing a questionnaire implies
the following aspects to consider:

- **Planning**: as the questionnaire is an indirect method (no face to face), it is crucial to properly plan it to make the most of it,
- **Sampling**: thoroughly target the correct sample to optimize the results on the research question, 
- **General instructions**: clear outline of what is expected from people filling the questionnaire,
- **Question wording**: make questions simple, specific, unambiguous, clear, not misleading,
- **Type of response required**: clarity on the structuring of responses (open, categories, multiple-choice, rating),
- **Sequencing of questions**: intuitive flow on the sequence of questions,
- **Layout**: easy of use, clear and appealing,
- **Demographic details**: defining what personal information is really needed,
- **Piloting**: trials to identify ambiguities, issues and errors,
- **Administration**: process to get access to the desired sample (distribution),
- **Data collection**:  process to collect the completed questionnaires (postage, internet),$
- **Data entry and screening**: conversion from questionnaire to usable data.

There are also many factors to take into consideration to make sure people fill the questionnaire appropriately to obtain good data. Generally, people might not be aware of specific aspects of a task (they don't realize everything they do, and how) or not recall certain information about a task (frequency, exposure). The time since exposure may also affect what can be observed as memory could be altered. Finally, observers and participants can have differences in their understanding and perception of certain aspects.

### Interview

Interviews, unlike questionnaires, happen **face to face** (or through vocal exchange) with a participant. It is a useful tool to collect detailed task related information, and thoroughly collect data with **flexibility**. However this method requires more time, and can be costly. Interviews are usually targeted to **smaller samples**. 

The aspects to consider for an interview are very similar to those for the questionnaires, but from a more practical point of view. Generally, an interview will require different planning regarding the instructions, the administration, and the data collection. Setting up the meeting, the location and the recording is important. It is also essential to prepare for the **interaction** with the participant, and behave appropriately to make sure the results are optimized. Finally, choosing the right type of interview is crucial. There are four types of interview:

- **Exploratory**: free-style in-depth,
- **Structured**: each interview is presented with exactly the same questions in the same order (no diversion),
- **Semi-structured**: open, allowing new ideas to be brought up during the interview, generally through a framework of themes to be explored,
- **Group**: multiple participants at once.

#### Exploratory

Exploratory interviews are used to "*probe*" participants and develop concepts by understanding how people think and feel about specific topics.
These interviews are "*free-style*" and spontaneous, with minimal intervention from the researcher.

#### Structured 

A structured interview is the most quantitative type of interview, providing a strong confidence in the results. By asking the exact same questions to every interviewee, a consistency is kept and the risk of diverting is the lowest.

#### Semi-structured

Semi-structured interviews address general themes and core questions, but allow for the interview to divert to broader and external contexts. Generally these interviews still require a set of questions regarding certain topics to always ensure a beneficial method. Being less "*accurate*", these interviews are widely used in qualitative research.

#### Group

Group interviews gather multiple participants, and sometimes multiple interviewers. The first benefit in doing such an interview is the obvious saving of time by combining participants. Of course a potential issue with this is the lack of depth, and the difficulty to maintain a structured interview. It is hence very important to limit the group interview to a maximum amount of participants and interviewers. The practical aspects must also be considered: group disposition, turn taking and general order.

#### Other interview techniques

- **Critical incident technique**: set of procedures used for collecting direct observations of human behavior that have critical significance and meet methodically defined criteria. These observations are used to solve practical problems and develop broad psychological principles. A critical incident can be described as one that makes a contribution, either positively or negatively, to an activity.
- **Critical decision method**: retrospective interview method that employs a set of cognitive probes to non-routine incidents that required expert judgment or decision making.
- **Verbal protocol reports**: concurrent and retrospective protocol reports used with cognitive tasks, to determine what workers are thinking about during tasks.

---

## Eliciting preferences

> Understanding the way people perceive, compare and prefer systems and products is an essential part of a design process. There are tools and methods used to identify these aspects in diverse contexts.

### Paired comparisons

When comparing multiple systems, the *paired comparisons* method can be used to *rank and identify general user preferences*. 
This method consists in presenting all possible pairs of the system (product) to every participant, in a random sequence. Each time, the participant
must indicate which system was preferred between the two.

#### Identifying the pairs

For \\(n\\) objects, there are \\( \frac{1}{2} \cdot n \cdot (n - 1)\\) possible pairs. In the example of 4 chairs, there a \\(1/2 * 4 * 3 = 6\\) possible pairs, that can be \\({AB, AC, BD, CB, CD, DA}.\\)

#### Filling the preference matrix

The preference matrix represents every pair and how many participants prefered one object to another (\\(x\\) prefered to \\(y\\)). The following preference matrix for the chairs, with 14 participants, is given:

|  | **A** | **B** | **C** | **D**
| :- | - | - | - | -
| **A** | - | 6 | 8 | 12
| **B** | 8 | - | 10 | 14
| **C** | 6 | 4 | - | 13
| **D** | 2 | 0 | 1 | -

#### Computing the probability matrix

To obtain results and identify the most (or least) preferred object, the probability matrix must be computed.
From the preference matrix, every item must be divided by the total number of participants \\(n\\), and empty items (same objects) replaced by \\(0.50\\).

|  | **A** | **B** | **C** | **D**
| :- | - | - | - | -
| **A** | 0.50 | 0.43 | 0.57 | 0.86
| **B** | 0.57 | 0.50 | 0.71 | 1.00
| **C** | 0.43 | 0.29 | 0.50 | 0.93
| **D** | 0.14 | 0.00 | 0.07 | 0.50
| \\(\sum\\) | 1.64 | 1.22 | 1.85 | 3.29

Using the last row, the sum of probabilities, the most preferred chaid is \\(D\\), and the least preferred one is \\(B\\).

#### Relative ranking

To rank the objects in relative levels, the use of standard scores, or *z-scores*, is required. To do so, the distance from the mean, here \\(0.50\\) must be extracted and used in the *normal distribution* table to get the *z-score*. If an item is above the mean, the *z-score* is positive, if it is under the mean the *z-score* is negative, and null otherwise.

|  | **A** | **B** | **C** | **D**
| :- | - | - | - | -
| **A** | 0.00 | -0.18 | 0.18 | 1.06
| **B** | 0.18 | 0.00 | 0.55 | 4.00
| **C** | -0.18 | -0.55 | 0.00 | 1.48
| **D** | -1.08 | -4.00 | -1.48 | 0.00
| \\(\bar{z}\\) | -0.27 | -1.18 | -0.19 | 1.64

The last row, the mean of the *z-scores*, represents a relative ranking:

\\[ B(-1.18) < A(-0.27) < C(-0.19) < D(1.64) \\]

### Repertory grid

The repertory grid is a tool to identify what **constructs are important** to a person in a system, product, job or establishement. It helps to understand 
and indivual's **interpretation** of his or her environment. Using a method of *triads*, this method compares elements of a topic (better, worse, extremes). These elements are put in a table that represents a person's perception of a certain topic. The data used to rate and rank the elements can be qualitative and quantitative. In practice, the repertory grid is a **structured and thorough method**, and can be applied to many contexts. Ideally used early in the design process, it might required more time to train the participaints and make sure the results are valid and reliable.

### Card sorting

The technique of card sorting, also called *concept sorting*, aims to understand how an individual sees the **relationships between a set of concepts**.
By sorting cards (items, elements) into piles, the participant explores the different ways in which concept are similar or different, using diverse system of sorting (categories, ordered hierarchy). Repeated many times, it can demonstrate many views of how **knowledge is organised**. The results can then be examined and analyzed to reveal relationships between concepts.

---

## Observartional methods

> Observing is an important skill when doing ergonomics work. It is important to understant *what* should be observed, and *how*?

### What?

Observation is first useful to become familiar with a task, get experience of work in a natural situation, a real setting. It is about observing the actions, postures, bahaviours, techniques, reactions and many more aspects of an activity. More than just observing the participants, it also essential to note the task sequences, timings, equipments and diverse resources, and the interactions between people.

### How?

Observing of an activity and collecting data can be done in many ways. An observation session can either be *formal* or *informal*, where a formal approach imposes a large amount of **structure** and direction on what is to be observed, whereas an informal session is less structured and allows the observer considerable **freedom** in what information is gathered ad how it is recorded. The observation can also be either *direct* or *indirect*. A direct observation is when the observer is present during the experiment, in real time. Indirect observation happens by accessing previous recording.

The role of the observer is a complex notion that can vary from **simple observer to complete participant**. While sometimes frowned upon from a scientifical point of view, the observer can decide to become a participant in the experiment. *Participant observation* presents advantages such as real experience for the observer (subjective experience), but also presents issues such as the analysis, that should already take place while collecting data. Participant observers can either hide the fact that they are carrying out a research (*the complete participant*), or make it clear from the start what is being observed (*the participant as observer*). Other possible roles are *the marginal participant*, when the observer plays the role of a passive participant in the "background", or *the observer-as-participant*, where the observer does not take part in the activity, but whose status as researcher is known to the participants.

### Issues

Whichever observation scheme is chosen, issues regarding ethics are raised. It is necessary to obtain permission from those who are being observed and recorded. In the context of *covert* studies (when the participants are not informed), there are obvious and strong ethical objections, that make that kind of activity more and more rare. Another issue the possible lengthy periods of observations necessary, followed by a large amount of information to analyze, requiring sufficient skills in the subject. There might also be practical issues, like getting the right point of view, access to spectific equipement, etc. Finally, the risk of a bias due to participant being aware of the experience and changing their usual methods is high.

### Collecting data

Collecting data during the experiment can be done with the following tools:

- **Notes**: writing down observations, thoughts and reflections, snippets of conservations, etc. While observing the activity, it is important
to look out for the following details:
    - *Ecology*: where the action takes place, layout of the space, location of actors and roles, equipments and artefacts used,
    - *Formal organisation*: plans or procedures,
    - *Transitions events*: important transition moments (arriving, leaving, etc),
    - *Arrangements of collaboration*: interactions between members (who talks to whom about what),
    - *Audio-visual data indexing*: times, sequence, making sense of digital data.
- **Interviews**: contextual interviews (not scripted), conversations about the the action conducted while observing it being done,
- **Aduio-visual recordings**: video cameras, audio recorders, still photography.
- **Digital logs**: messages, social media, conversations, systems, etc.

--- 

## Analysis of work and work systems

> Analyzing work is another important aspect of doing ergonomics work. But why do we analyze work? It is relevant to **understand the existing systems**, the task demands, its description, performance and the capabilities of people, to properly **design new systems**. It provides different ways of looking at work and systems through what must be done (*normative*), what is actually done (*descriptive*) and what could be done (*formative*).

### Terminology

Understanding concepts such as *task*, *goal* and *operation* is the first step towards work analysis:

- **Task**: a set of activities occuring about the same time, sharing some common purpose that is recognised by a task performer. Tasks are usually seen as the smallest useful description of a work activity, and can be defined as a goal to be achieved under certain conditions and with certain resources,
- **Goal**: a state to be achieved or maintained by an actor at a particular time, a goal is the object or aim of an action,
- **Operation**: units of behaviour undertaken in order to achieve a goal, specified in terms of a target system state,
- **Function**: a mode of action or activity by which a product fulfills its purpose,
- **Activity**: various actions or conduct in a given context, sometimes distinct from the term *task*.

### Task analysis

A task analysis is a study of what an operator is required to do, in terms of **actions** and **cognitive processes** to achieve a system goal. It is about describing activities, concerned with the examination of **human performance** in systems, both from the perspective of the **behaviour** of the human and the **factors** that shape performance.

The fundamental components of task analysis are:

- **Clarifying** the problem and **collecting** relevant information,
- **Analazing** and **representing** the information,
- **Defining** future use, solutions and outputs.

There are multiple forms of task analysis:

- **Data collection methods**: observation, critical incident, etc,
- **Task description**: representing data in specific formats (chart, hiearichical task analysis (HTA): decomposig a task into goals, sub-goals, operations an plans),
- **Task simulation**: computer modelling, computations, walk-throughs,
- **Task behaviour assessment**: eventualities, failures, effects,
- **Task requirements evaluation**: environment, checklists, surveys.