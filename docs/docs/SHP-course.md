# Studying Human Performance

**COURSE**

---

## Introduction

> **Ergonomics** is the scientific discipline cocerned with the understanding of interactions among humans and other elements of a system, in order to optimise human well-being and overall system performance.

The aim of this course is to be able to **analyse products and workplaces** using a range of different methods, to **compare and contrast different methodological approaches**, to **evaluate methods** and statistical techniques, to **demonstrate the application of specific methods** in practical contexts ; in order to solve Human Factors-related problems.

---

## Choosing methods

The understanding of methods is the core matter of this subject. A method is a "*way of proceeding or doing something*", and in Human Factors, allow for the collection of data. Methods need to be **clear**, **structured** and **repeatable**.

The **context** of the studies in which methods are used define purposes, roles and data that make up for many different methods. It is hence very important to understand the context of these studies, and how it impacts the use of methods.

### Study types

Three study types are observed: **Laboratory**, **Simulation** and **Field**. These types are compared with the following table:

|               | Laboratory/Simulation | Field 
| ------------- | ------------- |  -------
| Advantages    | More control  | Real task
| Disadvantages | Limited scope and accuracy  | Unplanned events (danger, interruptions)

### Affecting factors

In addition to the study type, there are numerous factors affecting the choice of methods:

- Amount of participants,
- Motivation (*research*, *consultancy*),
- Location,
- Objective,
- Types of desired results,
- Stakeholders, sponsors and funders.

### *Good* methods

The choice of a method significantly depends on the context of the study. However it doesn't define the quality of a method. *What is a good method?*
**Five requirements** define the quality of a method:

- **Validity**: does the method measure what it is supposed to measure?
- **Reliability**: is the method stable? (consistent over various measurements, between/within researchers),
- **Sensitivity**: is the method able to detect effects of interest? (the more sensible the more accurate),
- **Usability**: is the method easy to learn and implement?
- **Resources**: how expensive and demanding (cost, expertise) is the method? 

### Types of measure

When doing a study, the type of measures defines the methods used and the data collected. In most ergonomics works, the following measure types are assessed:

- **Performance**: Task achivement, errors,
- **Demands**: Task time, physical and mental workload,
- **Behaviour**: Body movements,
- **Knowledge**: Subjective responses to a *test* situation,
- **Opinions**: Ratings, preferences.

### Method types

A simple classification splits all available methods into **three categories**:

- Observation,
- Self report,
- Use of archival data.

For all methods, the **type of output** and **validity** are also differentiated. There is first the matter of **objective** or **subjective** validity:

- **Objective**: clamining the describe a true and correct reality, independent of those involved in the research process,
- **Subjective**: based on data derived from observations of events as they occur, or from interviews.

Finally, the data can be split in two categories:

- **Qualitative**: data classification of objects based on attributes and properties,
- **Quantitative**: data measuread and expressed numerically.

---

## Planning and designing studies

### Defining the problem, aim and hypotheses

The first step in designing a study is to clearly define the problem and issues that require investigation, and what will
be achived by doing it. This is usually represented by a system of **hypotheses**, or *statements of the predicted outcome*. As 
studies manipulate variables and data, the aim of these hypotheses is to predict, understand and validate the relationships between said variables.
Conventionally, there are two types of hypothesis:

- **Experimental**, or *H1*, that predicts a dependent relationship between variables,
- **Null**, or *H0*, that states that variables are not dependent (one does not impact the other).

### Identify the research variables

The said variables are split in three categories:

- **Independant variables** (*IV*): variables manipulated by the experimented, related to the individual, task, system or environment,
- **Dependant varaibles** (*DV*): varaibles being measured in the experiment, not under the control of the experimenter, possibly affected by the IVs,
- **Controlled variables**: variables that need to be kept constant during the experiment.

### Choose the research setting

The research setting (previously mentioned as *study type*), needs to be considered through the **advantages** and **disadvantages** between Laboratory and Field studies, as well as if it is actually *possible* to implement one based on the nature of the study. The following table describes the key elements for choosing:

**Field**

| Advantages    | Disadvantage  |
| ------------- | ------------- |  
| Realistic     | Hard to set up |
| Easier to generalise results | May take longer
| Real participants | Difficulty to access real participants
| -- | Many uncontrolled variables
| -- | Harder to control variables

**Laboratory**

| Advantages    | Disadvantage  |
| ------------- | ------------- |  
| Easy to set up | Artificial
| Shorter | Participants less motivated
| Easy to control variables | May not be able to controll all extraneous variables
| Easy to perform comparative tests | May be expensive

### Select the participants sample

It is important to properly select the **sample**, the sall group that is representative of the **population**. This sample must be the most representative of the population possible, in order to make more general statements about the results.

There are multiple types of sampling, depending on if the notion of probability accuracy is desired. The three major ones are:

- **Random**: selecting random participants, with each particiant having an equal chance of being selected,
- **Systematic**: selecting every *nth* participant,
- **Stratified random**: first diving the population into meaningful groups, then selecting randomly.

In other situtions, the participants are selected in a more *favored* way, when the basic selection techniques seen previously are not precise enough and the sample needs to be very specific. The **non-probability** sample techniques are:

- **Purposive**: satisfying the specific needs of a project,
- **Conveniance sampling**: nearest, easiest, cheapest, most convenient.

Finally, the resources and costs required to mobilize a sample need to be balanced with the potential results, and the confidence that
the results will be significant.

### Defining the experimental design

The number and arrangement of the variables is an important part of the study. The aim is to ensure that the IVs are the only systematic difference between
the experimental groups, also called the **internal validity**. It is also important to consider the measurement of the DVs, such as the data is commonly quantitative, easy to collect, valid, reliable, senstive and ethical.

### Allocate participants to the experimental conditions

There are two ways to allocate and distribute the participants across the IVs:

- **Within**: every participant completes every experimental condition,
- **Between**: different participants are allocated to each experimental condition.

### Ethics

When doing studies with real participants, ethics play an important part in carrying out the experiments. It is required that they should give **informed consent**, based on sufficient information on the study (goals, duration, instruction, type of data collected, use of data). They should also be ensured protection from harm, privacy and a right to withdraw at any moment.

--- 

## Conducting the study

### Preparing the experiment

Planning an preparing before conducting the study can be a lengthy process, but is necessary. Once designed, piloting the study with *trial* members allows to make sure everything is in order and as desired. The practical details such as appointements, timescales or idenfication must be thoroughly planned. Finally the various types of equipment required for the experiments must be properly prepared in order to conduct the study with consistency.

### Analyzing the data

Once the data is collected, analyzing it is a complex process. A common way to do so is the following:

1. **Transcribe**, **examine** and **outline** the data using tools such as charts, tables ; observing patterns, distributions and tendencies,
2. **Identify** the type of data: nominal (categories), ordinal (ordered) or interval (ordered with equal intervals).
3. **Statiscally test** the data based on the purpose of the study and the experimental design,
4. **Draw conclusions**.

### Presenting results and drawing conclusions

Results can be represented visually through charts, figures and tables. *Descriptive* and *inferential* statistics are also commonly used.
Based on the drawn conslusions (*reject*, *fail to reject*), a wider discussion must be made regarding the strength of the findings, and how they can be generalized to other contexts.

--- 

## Self report methods